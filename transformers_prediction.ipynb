{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerModel\n",
    "\n",
    "# Initializing a Time Series Transformer configuration with 12 time steps for prediction\n",
    "configuration = TimeSeriesTransformerConfig(prediction_length=12)\n",
    "\n",
    "# Randomly initializing a model (with random weights) from the configuration\n",
    "model = TimeSeriesTransformerModel(configuration)\n",
    "\n",
    "# Accessing the model configuration\n",
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesTransformerConfig {\n",
       "  \"activation_dropout\": 0.1,\n",
       "  \"activation_function\": \"gelu\",\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"cardinality\": [\n",
       "    0\n",
       "  ],\n",
       "  \"context_length\": 12,\n",
       "  \"d_model\": 64,\n",
       "  \"decoder_attention_heads\": 2,\n",
       "  \"decoder_ffn_dim\": 32,\n",
       "  \"decoder_layerdrop\": 0.1,\n",
       "  \"decoder_layers\": 2,\n",
       "  \"distribution_output\": \"student_t\",\n",
       "  \"dropout\": 0.1,\n",
       "  \"embedding_dimension\": [\n",
       "    0\n",
       "  ],\n",
       "  \"encoder_attention_heads\": 2,\n",
       "  \"encoder_ffn_dim\": 32,\n",
       "  \"encoder_layerdrop\": 0.1,\n",
       "  \"encoder_layers\": 2,\n",
       "  \"feature_size\": 9,\n",
       "  \"init_std\": 0.02,\n",
       "  \"input_size\": 1,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"lags_sequence\": [\n",
       "    1,\n",
       "    2,\n",
       "    3,\n",
       "    4,\n",
       "    5,\n",
       "    6,\n",
       "    7\n",
       "  ],\n",
       "  \"loss\": \"nll\",\n",
       "  \"model_type\": \"time_series_transformer\",\n",
       "  \"num_dynamic_real_features\": 0,\n",
       "  \"num_parallel_samples\": 100,\n",
       "  \"num_static_categorical_features\": 0,\n",
       "  \"num_static_real_features\": 0,\n",
       "  \"num_time_features\": 0,\n",
       "  \"prediction_length\": 12,\n",
       "  \"scaling\": \"mean\",\n",
       "  \"transformers_version\": \"4.37.2\",\n",
       "  \"use_cache\": true\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerModel\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"hf-internal-testing/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerModel.from_pretrained(\"huggingface/time-series-transformer-tourism-monthly\")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "last_hidden_state = outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import torch\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "\n",
    "file = hf_hub_download(\n",
    "    repo_id=\"hf-internal-testing/tourism-monthly-batch\", filename=\"train-batch.pt\", repo_type=\"dataset\"\n",
    ")\n",
    "batch = torch.load(file)\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\n",
    "    \"huggingface/time-series-transformer-tourism-monthly\"\n",
    ")\n",
    "\n",
    "# during training, one provides both past and future values\n",
    "# as well as possible additional features\n",
    "outputs = model(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_values=batch[\"future_values\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "\n",
    "# during inference, one only provides past values\n",
    "# as well as possible additional features\n",
    "# the model autoregressively generates future values\n",
    "outputs = model.generate(\n",
    "    past_values=batch[\"past_values\"],\n",
    "    past_time_features=batch[\"past_time_features\"],\n",
    "    past_observed_mask=batch[\"past_observed_mask\"],\n",
    "    static_categorical_features=batch[\"static_categorical_features\"],\n",
    "    static_real_features=batch[\"static_real_features\"],\n",
    "    future_time_features=batch[\"future_time_features\"],\n",
    ")\n",
    "\n",
    "mean_prediction = outputs.sequences.mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[26567.8809, 33460.0039, 33477.6836,  ..., 33134.7539, 36102.3008,\n",
       "         27315.9121],\n",
       "        [25367.9492, 34572.5430, 47729.1797,  ..., 25901.6621, 26090.9219,\n",
       "         23458.9043],\n",
       "        [ 1063.4843,  1035.4250,  1185.3597,  ...,  2187.8481,  1874.3115,\n",
       "          1784.1362],\n",
       "        ...,\n",
       "        [ 2820.5125,  3764.5811,  3606.7627,  ...,  3872.6213,  4121.8154,\n",
       "          4569.5708],\n",
       "        [  847.6557,   844.8374,   241.7009,  ...,   614.1525,  1364.0256,\n",
       "          1346.4597],\n",
       "        [  393.9912,   552.5994,   354.8450,  ...,   358.3022,   358.7657,\n",
       "           461.4601]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_prediction\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
