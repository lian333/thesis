{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20640, 8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load California Housing dataset\n",
    "data = fetch_california_housing()\n",
    "X = data.data\n",
    "feature=data.feature_names\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14912\\4023242320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfeature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'feature_names'"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "feature=X.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_generator():\n",
    "    noise_dim = 100\n",
    "    noise_input = Input(shape=(noise_dim,))\n",
    "    hidden = Dense(128, activation='LeakyReLU')(noise_input)\n",
    "    output = Dense(X_scaled.shape[1], activation='linear')(hidden)\n",
    "    model = Model(inputs=noise_input, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_discriminator():\n",
    "    data_input = Input(shape=(X_scaled.shape[1],))\n",
    "    hidden = Dense(128, activation='LeakyReLU')(data_input)\n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=data_input, outputs=output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cGAN\n",
    "def create_cgan(generator, discriminator):\n",
    "    noise_input = Input(shape=(100,))\n",
    "    generated_data = generator(noise_input)\n",
    "    validity = discriminator(generated_data)\n",
    "    model = Model(inputs=noise_input, outputs=validity)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the Discriminator\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
    "\n",
    "# Create the Generator\n",
    "generator = create_generator()\n",
    "\n",
    "\n",
    "gan = create_cgan(generator, discriminator)\n",
    "# Ensure that only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 0, Discriminator Loss: 0.666893720626831, Generator Loss: 0.7720139622688293\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "training_steps = 100\n",
    "\n",
    "for step in range(training_steps):\n",
    "    # Select a random batch of real data\n",
    "    idx = np.random.randint(0, X_scaled.shape[0], batch_size)\n",
    "    real_data = X_scaled[idx]\n",
    "\n",
    "    # Generate a batch of new data\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    generated_data = generator.predict(noise)\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_loss = discriminator.train_on_batch(real_data, np.ones((batch_size, 1)))\n",
    "    fake_loss = discriminator.train_on_batch(generated_data, np.zeros((batch_size, 1)))\n",
    "    discriminator_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "    # Train the generator\n",
    "    generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        print(f\"Step: {step}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 784us/step\n"
     ]
    }
   ],
   "source": [
    "num_synthetic_samples = 1000\n",
    "noise = np.random.normal(0, 1, (num_synthetic_samples, 100))\n",
    "synthetic_data = generator.predict(noise)\n",
    "synthetic_data_unscaled = scaler.inverse_transform(synthetic_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "      MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  -0.363010  0.284385 -0.854360  -0.565244   -0.828770  0.206482 -0.474941   \n",
      "1  -0.225982 -0.054308 -0.462691  -0.961661   -0.016457 -0.161887 -0.588831   \n",
      "2  -0.023404  0.709455 -0.746130  -0.478682   -0.679322  0.143626 -0.425006   \n",
      "3   0.241273  0.391960 -0.561241   0.137048    0.256928 -0.643878 -0.158072   \n",
      "4   0.898096  0.511746 -0.614307   0.167789   -0.723261 -0.587407 -0.423459   \n",
      "5  -0.075284 -0.231068 -1.124324  -0.380837   -0.104739 -0.579997 -0.775675   \n",
      "6   0.303988  0.349243 -0.479456   0.108758   -0.417100 -0.663867 -1.164432   \n",
      "7  -0.060566  0.323776 -0.252997   0.227646   -0.532423 -0.616802 -0.502853   \n",
      "8  -0.682518  0.042494 -0.819971  -1.072586    0.644965  0.037707  0.485268   \n",
      "9   0.467033  0.968230  0.349988  -0.385955   -0.767810  0.347050 -0.246655   \n",
      "10  1.060199  0.328364  0.041503   0.696764   -0.747908  0.457307 -0.261987   \n",
      "11  0.198800  0.001134 -0.132606  -0.213431    0.295030  0.562883 -0.101889   \n",
      "12 -0.330711 -0.127177 -0.411058  -0.610331   -0.451820 -0.229452  0.110516   \n",
      "13 -0.117092  1.178317 -0.558430  -1.161811   -1.226677 -0.068016 -0.953640   \n",
      "14  0.719185  0.585673 -0.047375   0.032391   -1.274940  0.091495 -0.969462   \n",
      "15  0.831516  1.454070 -0.236968   0.410235   -1.636145 -1.132509 -1.760393   \n",
      "16  0.513527  1.717339 -0.275000  -0.247526   -2.924169  0.489246 -1.645918   \n",
      "17 -0.058951  0.967695 -0.339521  -0.202453   -1.020127 -0.723439 -0.953159   \n",
      "18  0.298387  1.953920  0.404498  -1.112742   -0.673729  0.684240 -0.298194   \n",
      "19 -0.978864 -0.490632 -0.611411  -1.269539    1.107252  0.836676  0.464287   \n",
      "20  0.439514  0.699657 -0.444690  -0.073642   -0.554512 -0.477161 -0.164374   \n",
      "21  0.416515  0.517622 -0.384031  -0.446593   -0.790071 -0.341437 -0.498781   \n",
      "22 -0.479542  1.517791 -0.596570  -1.003368   -2.647192  0.479520 -1.234037   \n",
      "23  0.263773 -0.023427 -1.211773  -0.025261   -0.336477  0.342643 -0.349652   \n",
      "24 -0.601728  0.202622 -1.002738  -1.410290   -2.048826  0.493776 -0.977027   \n",
      "25 -0.029235  1.442390  0.109548  -0.816046    0.938478 -0.273377 -0.197157   \n",
      "26  0.029181  0.444207 -0.702904   0.000490   -0.885517  0.025814 -0.724847   \n",
      "27 -0.058812  0.504442 -0.538982  -0.951088   -1.566922  0.224300 -1.033536   \n",
      "28 -0.569374  0.076913 -1.006339  -0.896448   -0.526549  0.159211 -0.990707   \n",
      "29 -0.299898  0.906388  0.305843  -0.503216    0.110810  0.312662 -0.359784   \n",
      "30 -0.473710  0.903216 -0.602375  -0.447132   -0.426556  0.414664 -0.669751   \n",
      "31  0.007778  1.052443 -0.532341  -0.054868   -2.069172 -0.432711 -2.232700   \n",
      "32  0.405366  1.196547 -0.511240  -0.289601   -0.442507 -0.375161 -0.671914   \n",
      "33 -0.377485  0.839246 -0.456829  -0.848173   -0.826533 -0.258631 -0.759049   \n",
      "34 -0.451873  0.094531 -0.858563   0.199357    0.199145 -1.116506 -0.516966   \n",
      "35 -0.021176  0.449488 -0.579427  -0.447480   -1.426829 -0.196394 -1.449379   \n",
      "36  0.078436  0.829154  0.288747  -0.142608   -0.007231 -0.348322 -0.565330   \n",
      "37  0.355836  0.922064 -0.077866  -0.430200   -0.373079 -0.380183  0.156321   \n",
      "38 -0.324063  0.292310 -1.369238  -0.811114   -1.248613  0.154070 -0.471971   \n",
      "39  0.373249  0.644496 -1.065597  -0.187961   -1.120068 -0.061451 -1.285890   \n",
      "\n",
      "    Longitude  \n",
      "0    0.693263  \n",
      "1    0.538360  \n",
      "2    1.315765  \n",
      "3    0.419354  \n",
      "4    0.850381  \n",
      "5    0.518527  \n",
      "6    0.376804  \n",
      "7    0.110860  \n",
      "8    0.614323  \n",
      "9    1.539922  \n",
      "10   0.930647  \n",
      "11   0.302517  \n",
      "12   0.484228  \n",
      "13   1.096692  \n",
      "14   0.920417  \n",
      "15   1.745131  \n",
      "16   2.181075  \n",
      "17   1.388774  \n",
      "18   2.217184  \n",
      "19   0.355446  \n",
      "20   1.123274  \n",
      "21   1.202685  \n",
      "22   1.789406  \n",
      "23   0.118926  \n",
      "24   1.157733  \n",
      "25   0.896379  \n",
      "26   0.815901  \n",
      "27   1.716614  \n",
      "28   0.578785  \n",
      "29   0.638447  \n",
      "30   1.391275  \n",
      "31   1.455672  \n",
      "32   0.454921  \n",
      "33   1.537824  \n",
      "34  -0.190364  \n",
      "35   0.892120  \n",
      "36   0.744532  \n",
      "37   1.036265  \n",
      "38   0.314580  \n",
      "39   0.823920  \n"
     ]
    }
   ],
   "source": [
    "# Generate instances for a given class\n",
    "def generate_data(generator, num_instances):\n",
    "    noise = np.random.normal(0, 1, (num_instances, 100))\n",
    "    generated_data = generator.predict(noise)\n",
    "    return pd.DataFrame(generated_data,columns=feature)\n",
    "\n",
    "# Generate 40 instances of class 1\n",
    "generated_data = generate_data(generator, 40)\n",
    "synthetic_data = pd.DataFrame(generated_data)\n",
    "synthetic_data.to_csv(r'C:\\Users\\lia68085\\test\\synthetic_house_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming synthetic_data_unscaled is your generated dataset\n",
    "# And assuming the last column of the dataset represents median house values\n",
    "\n",
    "# Define a threshold for categorizing high and low value areas\n",
    "value_threshold = np.median(synthetic_data_unscaled[:, -1])\n",
    "\n",
    "# Assign labels based on the threshold\n",
    "labels = ['High' if value > value_threshold else 'Low' for value in synthetic_data_unscaled[:, -1]]\n",
    "\n",
    "# Add labels to your DataFrame\n",
    "import pandas as pd\n",
    "synthetic_df = pd.DataFrame(synthetic_data_unscaled, columns=data.feature_names)\n",
    "synthetic_df['Label'] = labels\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
